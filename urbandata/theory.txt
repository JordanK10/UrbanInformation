
We start by deriving a general theory of growth rates in terms of informational quantities.  Here, information means an agent's predictive knowledge of event probabilities in a noisy environment.
Agents seek to maximize the growth of their resources over time by investing in a set of possible events in their environment using their individual knowledge.
Agent's knowledge is subjective, as it is formed by the agent's own experience, model of the world and expectations (``beliefs"), which are assumed here not to be shared or compared with other agents.  The agent's beliefs are adjusted by observing environmental outcomes in time through an iterative process of (Bayesian) learning.
After developing the general framework, we illustrate these dynamics using a multinomial model of discrete environmental states and choice, for which we derive closed-form expressions for the average resource growth rate and volatility in terms of information-theoretic quantities. We will then identify the general circumstance when this learning process dynamically attenuates inequality in resource growth rates across populations.

%Logically complete with no caveats^

\begin{figure*}
\quad
\includegraphics[width=.95\textwidth]{ learn_figs/Figure1.pdf} \\
\caption{\label{fig:Fig1} General dynamics of learning and growth: Agents obtain resources from their environment based on the quality of their information. \textbf{A.} At each time step, \textbf{a}. the agent's private channel (memory, senses) outputs a signal $s\in S$ with probability $P(s)$. \textbf{b}. The agent observes the state $s$, \textbf{c}. and consults their belief for the  conditional outcome probability of the environment, $X(E|s)$. \textbf{d.} The agent makes proportional resource allocations on all possible outcomes $B(E|s)$. \textbf{f,e.} The true event $e\in E$ is revealed from the environment with probability $P(e)$, and \textbf{g.} the agent receives a payout proportional to the marginal probability of $e$. \textbf{B.} In a population simulation, $N$ agents independently sample private signals and invest in events sampled from the same environment.}
\end{figure*}

\subsection*{Growth from Information}

We consider a population of $i=1,...,N$ agents, each with initial resources $r_i$ that can be (re)invested into the set of outcomes of their environment to generate returns.
The agents have access to a private signal $s\in S$, which they use as a predictor to invest resources in events $e\in E$ generated by their environment.
The set of signals and events are described by the joint probability distribution, $P(E,S)$ with marginals $P(E)$ and $P(S)$.  

At every time step, each agent observes its own  signal $s$, and allocates resources $r$ on events following a vector $B(E|s)$, such that $\sum_e B(e|s) =1, ~e\in E$.
As the event $e$ is revealed, the agent is awarded returns, $w_e$ for the fraction of resources invested in the correct outcome, $B(e|s)r_i$. After $n$ steps, the agent's total resources (wealth) are

\begin{equation}\label{jordanbets}
r_{n}=r_i\prod_{j=1}^n B(e_j|s_j)w_{e_j}=r_i\prod_{s,e}\big[B(e|s)w_e\big]^{W_{s,e}},
\end{equation}

\noindent where $W_{s,e}$ is the number of occurrences ("wins") of $s,e$. 
By the law of large numbers, $\frac{W_{s,e}}{n}\rightarrow P(s,e)$ as $n\rightarrow\infty$.  It follows that the average growth rate of resources over large $n$ steps is 

\begin{equation}\label{eq:growthrate}
    \gamma_i\equiv\frac{1}{n}\log \frac{r_n}{r_i}\approx\sum_{e,s}P(s,e)\log[B(e|s)w_e].
\end{equation}

Kelly showed that the maximal growth rate as $n \rightarrow \infty$, obtained by maximizing Eq.~(\ref{eq:growthrate}) with relation to $B(E|S)$, results in an allocation mirroring the conditional probability, $B(E|S)=P(E|S)$.  This maximum growth rate is the mutual information, $\gamma_{max}=I(E,S)$ when the odds are "fair", $w_e=1/P(e)$ \cite{kelly}. 

Typical agents do not start out with perfect knowledge. In this case, agents must invest resources using their best estimate for the conditional probability, $X(E|S)\neq P(E|S)$. Then, their resource growth rate will be lower than the maximum. This can still be written in terms of informational quantities as the Kelly growth rate (SM 1),

\begin{equation}\label{KGR}
    \gamma=I(E;S)-\mathrm{E}_{s}\big(D_{KL}\big[P(E|s)||X(E|s)\big]\big).
\end{equation}
\noindent where $\textrm{E}_s$ is an expectation value over the states of the signal, and $D_{KL}\big[P(E|s)||X(E|s)\big]=\sum_e P(e|s)\log\frac{P(e|s)}{X(e|s)}\geq 0$ is the Kullback-Leibler divergence, expressing how similar the two distributions in its inputs are.
This general result shows that agents with better information will experience greater resource growth rates, as long as they invest optimally \cite{algoet1988asymptotic}.  
These compounding dynamics are illustrated in Fig. \ref{fig:Fig1}. We also see that this setup allows us to consider agents with different knowledge, corresponding to skill heterogeneity within a population. We will discuss other general issues of innovation and structural position as we introduce learning in populations below.

We note that in reality, people may be in debt, typically leading to a negative component of their growth rate due to interest payments.
We do not consider this situation here, except to point out that if such a component is constant it does not affect our analysis. If, however, the loan rate can be reduced via better information, it will add another dimension to the optimization of the overall growth rate.

We will now illustrate these general results using a specific, stationary multinomial model.
While the theory is developed for general environmental dynamics, its limitation to a stationary environment will allow us to derive quantities of mean growth rate and volatility, familiar to GBM, in closed-form and establish the parallels to most wealth-growth models.
This model will allow us to then illustrate and simulate the population dynamics of growth and inequality among agents with heterogeneous information. 
Later, we will also show how agents can improve their information optimally over time through a process of iterative Bayesian learning.

\subsubsection*{Multinomial Choice Model}

%Here we construct a signal and environment distribution that produces a convenient, closed-form expression for the growth rate and volatility.
%We demonstrate that in the time domain, the dynamics of growth resemble the behavior of GBM models commonly used to study wealth distributions.
%The environment is configured such that agents are rewarded resources for correctly predicting the event, and are penalized in equal rate for picking any other event. 
%This joint distributed event space reduces an agent's reward to a binary choice between the correct or incorrect event, as incorrect choices are degenerate. 
%Agents would then only need a single parameter to estimate the conditional probability, $p$, simplifying the description of growth rate, and ultimately the inference process. 

Consider the space of signals $S$ and environmental states $E$ of equal size $l$, with  outcomes $s,e\in 1,...,l$ and degenerate, multinomial conditional probability

\begin{equation}\label{app:ppos}
    P(e|s)= f(p,l)=   
    \begin{cases}
        p & \text{if } s=e\\
        \frac{1-p}{l-1}& \text{if } s\neq e,
    \end{cases}
\end{equation}
\noindent  where $0< p< 1$ is the binomial probability of guessing the correct environmental outcome. For simplicity, we assumed that the probability of a correct guess is independent of $l$. The distribution has uniform marginals, $P(e)=1/l$ and $P(s)=1/l$, for all signals and events, such that $P(s|e)=P(e|s)$ via Bayes' rule. 

 With these choices, we can derive expressions for the relevant informational quantities in closed-form. The mutual information between an agent's signals and environmental outcomes is then $I(E;S)=\log l+p\log p+(1-p)\log\frac{1-p}{l-1}$ (APP \ref{appinf}).
As the simplest illustration, for a binary choice, $l=2$, the first term gives 1 bit of entropy of the environment and the remaining terms give the conditional entropy, expressing how well an agent could know the environment given their signal.
In the limit $p\rightarrow 1$, the signal gives agents perfect knowledge of $P(E)$.
  
So far we considered that the agent has perfect knowledge of the joint distribution of the signals and the environment. 
When this is not the case, we can write a parametric expression of the agent's ignorance in terms of an estimated binomial probability $x \neq p$.
The agent's likelihood model of the conditional probability is then $X(e|s)= f(x,l)$. The divergence term of Eq.~\ref{KGR} becomes the divergence between $f(p,l)$ and $f(x,l)$ averaged over all signals, $\textrm{E}_s\big[D_{KL}\big]=p\log \frac p {x}+(1-p)\log\frac{1-p}{1-x}$. Subtracting the mutual information by this term yields the agent's actual growth rate under imperfect information as (SI \ref{simplegrowth})

\begin{equation}
    \gamma=\log l+p\log x+(1-p)\log\frac{1-x}{l-1}.
\end{equation}
\begin{figure*}
\vspace{-.4cm}
\quad
\centering
    \hspace{-.3cm}\includegraphics[width=\textwidth]{ learn_figs/Figure2.pdf}
\caption{\label{fig:Fig2} Example of parameters and dynamics for wealth growth without learning.
The growth rate and volatility are computed analytically for a discrete multinomial environment, reproducing the limit of GBM dynamics. \textbf{A}. For $p=.7$, the growth rate maximizes at $x=.7$, decreases as $x$ diverges from $p$, and scales with $l$. The parameter $l=2$ provides a realistic range of average growth rates. 
\textbf{B}. Monte Carlo simulations with $N=388$ homogeneous agents, all with $\gamma(x)=.03$ and $r_0=1$. 
The expected mean (red) predicted by $\gamma=.03$ and population mean (orange) overlap in value. The blue lines represent the 95\% confidence interval. 
\textit{Inset}: The resource histogram is fit to a log-normal distribution of the same growth and volatility parameters.
\textbf{C}. Volatility is minimized at $x=l/2$ and increases monotonically in either direction. Volatility increases more rapidly at higher values of $l$.
\textbf{D}.  Over time, $\Delta_\gamma\rightarrow 0$ as agents' growth rates approach the Kelly growth rate. The average agent converges to within 15\% the expected mean at $t\approx 80$. }
\end{figure*}

\noindent This expression is plotted in Fig. \ref{fig:Fig2}A as a function of $x$ for various $l$ values and fixed $p$.  We see that increasing the size of the event space, $l$, reduces the probability of any individual outcome, increasing the payouts and the Kelly growth rate. The maximal growth rate is obtained when $E_e [ D_{KL}] \rightarrow 0$, when $x\rightarrow p$. Conversely, $\gamma \rightarrow 0$ when $p\rightarrow 1/l$, indicating the signal and the environment have become statistically independent. 

Treating $\gamma$ as the expected resource growth rate, the volatility is calculated as the second moment of the growth process. The volatility squared (variance) is given as (APP \ref{simplevariance})

\begin{equation}
\sigma^2={p(1-p)}\log^2\frac{x(l-1)}{1-x}.
\end{equation}

\noindent This expression is shown in Fig. \ref{fig:Fig2}C. The  volatility vanishes in the limit $x\rightarrow 1/l$, corresponding to when agents invest indiscriminately with equal probability in all possible event types. A larger $l$ increases the magnitude of the growth rate, but also the volatility.  The volatility is highest when $p\rightarrow 1/2$ and the environment is most uncertain. In any case, the agents feel surest of the outcomes when $x\rightarrow 0$,  or $x\rightarrow 1$.

%%% does this need a break here?

Kelly's formulation describes the average growth rate of resources over a large number of discrete  investments~\cite{kelly}. To derive a growth process in time, we average over $\omega$ bets per unit time, such that $\Delta t=1/\omega$ is the  interval of time between investment periods. 
Returns at time $t+\Delta t$ are then the mean of all investment returns earned in the time interval $[t,t+\Delta t]$.
In the limit $\omega\rightarrow\infty$, as the agent makes continuous allocations,  $r_n\rightarrow r(t)$ and $\gamma$ describe the average growth rate. We consider $t\approx 10^{-2} yr$ (i.e. 1\% a year)  so that our simulated results are comparable to previous work based on yearly growth rates of the order of a few percent. Volatility is reduced $\sigma_t=\sigma_n/\sqrt\omega$ as fluctuations are averaged out in each time step (SM 10). 

Fig. \ref{fig:Fig2}C demonstrates the two investment regimes for each value of $\gamma$, where the growth rate maps to either high or low volatility depending on the value of $x$.
Investments with $x>p$, which we describe as \textit{aggressive}, overestimate the dependence between the signal and environment.
Under this condition, agents invest relatively more on diagonal outcomes and experience large gains or losses  resulting in higher volatility.
With $x<p$, which we denote \textit{conservative}, agents underestimate $p$  and distribute their wealth more equally across all outcomes, resulting in less volatility.
Agents can also experience $\gamma=0$ at two values of $x$: In the trivial limit, as $x\rightarrow 1/l$, signals and agent investments become statistically independent. 
The other trivial case can be solved for numerically when $\gamma=0$. 
%The simulation results demonstrated in this paper assume a strictly under-betting population. 


With given $x$ independent of time, the dynamics reduce to the well-known behavior of geometric Brownian motion (GBM) with drift.  Fig \ref{fig:Fig2}B shows the dynamics of a population of agents with homogeneous (non-time dependent) parameters evolved using a Monte-Carlo simulation. 
In this particular situation, mean population resources grow with $\langle r(t)\rangle=\frac{1}{N}\sum_i r_i(t)=\exp[\gamma t]$, in agreement with \cite{bettencourt}